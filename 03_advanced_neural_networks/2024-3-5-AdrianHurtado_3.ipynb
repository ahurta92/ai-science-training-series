{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:49.366318211Z",
     "start_time": "2024-02-22T21:15:47.560283565Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc907c456d5a66d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:49.382845540Z",
     "start_time": "2024-02-22T21:15:49.379378091Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.transforms import v2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6418e67cee10648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:50.483216869Z",
     "start_time": "2024-02-22T21:15:49.379520325Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 170498071/170498071 [00:01<00:00, 104124716.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=v2.Compose([\n",
    "        v2.ToTensor(),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomResizedCrop(size=32, scale=(0.85, 1.0), antialias=False),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    ])\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=v2.Compose([\n",
    "        v2.ToTensor(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# split the training data into training and validation\n",
    "training_data, validation_data = torch.utils.data.random_split(training_data, [.8, .2], generator=torch.Generator().manual_seed(42))\n",
    "batch_size = 128\n",
    "\n",
    "# Create the dataloaders\n",
    "\n",
    "train_dataloader = DataLoader(training_data,\n",
    "                              batch_size=batch_size,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)\n",
    "validation_dataloader = DataLoader(validation_data,\n",
    "                                   batch_size=batch_size,\n",
    "                                   pin_memory=True,  # copy the data to the GPU\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=4)  # number of subprocesses to use for data loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ae569cf589332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.085870399Z",
     "start_time": "2024-02-22T21:15:50.483567162Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c78289d71a5d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.086426714Z",
     "start_time": "2024-02-22T21:15:51.083335957Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a2af455b60f988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.100515378Z",
     "start_time": "2024-02-22T21:15:51.086144959Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(X, Y):\n",
    "    # CIFAR-10 is *color*\n",
    "    return X.view(-1, 3, 32, 32).to(device), Y.to(device)\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "\n",
    "train_dataloader = WrappedDataLoader(train_dataloader, preprocess)\n",
    "validation_dataloader = WrappedDataLoader(validation_dataloader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66aded01-6155-4052-bb44-1f62c6c2cefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.133065213Z",
     "start_time": "2024-02-22T21:15:51.105871866Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Lets try a downsampler with convol\n",
    "class Downsampler(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        kernel_size=3\n",
    "        stride=1\n",
    "        padding=1 # keep the same size at the end\n",
    "        super(Downsampler, self).__init__()\n",
    "\n",
    "        layers=[\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2)]\n",
    "        self.norm = nn.LayerNorm([in_channels,])\n",
    "        self.downsample=nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.downsample(self.norm(inputs))\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"This block of operations is loosely based on this paper:\n",
    "    start with an input with a 7 by 7 kernel, however with same padding it will not change the size of the image.\n",
    "    Then we apply a normalization layer, and follow with 4 filters, aka patches,per channel.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, shape):\n",
    "        super(ConvNextBlock, self).__init__()\n",
    "        # Depthwise, seperable convolution with a large number of output filters:\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=in_channels,\n",
    "                               groups=in_channels,# this is what makes it seperable? in_channel number of groups\n",
    "                               kernel_size=[7, 7],\n",
    "                               padding='same')# keep the same size\n",
    "        #This is like an expand, \n",
    "\n",
    "        self.norm = nn.LayerNorm([in_channels, *shape])\n",
    "        # Two more convolutions:\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=4 * in_channels,\n",
    "                               kernel_size=1)\n",
    "        # Then we do the unrolling of the patches, and apply a non-linear activation function.\n",
    "        self.conv3 = nn.Conv2d(in_channels=4 * in_channels,\n",
    "                               out_channels=in_channels,\n",
    "                               kernel_size=1\n",
    "                               )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.norm(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "        x = self.conv3(x)\n",
    "        # This makes it a residual network:\n",
    "        return x + inputs\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_initial_filters, n_stages, blocks_per_stage):\n",
    "        super(Classifier, self).__init__()\n",
    "        # our first example is set with 64,4,2 meaning 64 initial filters, 4 stages, 2 blocks per stage\n",
    "        # This is a downsampling convolution that will produce patches of output.\n",
    "        # This is similar to what vision transformers do to tokenize the images.\n",
    "        self.stem = nn.Conv2d(in_channels=3,\n",
    "                              out_channels=n_initial_filters,\n",
    "                              kernel_size=1,\n",
    "                              stride=1)\n",
    "        # Here is the initial convolution which takes our 32 x 32 image with 3 channels and \n",
    "        # converts it to 64 channels with a 1x1 convolution\n",
    "\n",
    "        # In other words, this stem is a patching operation that converts the input image into a set of patches.\n",
    "        # 3 to 64.  maybe here it makes sense to make n_intial_filters = 3 * filter_per_channel.. say 32\n",
    "\n",
    "        current_shape = [32, 32]\n",
    "        self.norm1 = nn.LayerNorm([n_initial_filters, *current_shape])\n",
    "        # self.norm1 = WrappedLayerNorm()\n",
    "        current_n_filters = n_initial_filters\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for i, n_blocks in enumerate(range(n_stages)):\n",
    "            # Add a convnext block series:\n",
    "            for _ in range(blocks_per_stage):\n",
    "                self.layers.append(ConvNextBlock(in_channels=current_n_filters, shape=current_shape))\n",
    "            # Add a downsampling layer:\n",
    "            if i != n_stages - 1:\n",
    "                # Skip downsampling if it's the last layer!\n",
    "                self.layers.append(Downsampler(\n",
    "                    in_channels=current_n_filters,\n",
    "                    out_channels=2 * current_n_filters,\n",
    "                )\n",
    "                )\n",
    "                # Double the number of filters:\n",
    "                current_n_filters = 2 * current_n_filters\n",
    "                # Cut the shape in half:\n",
    "                current_shape = [cs // 2 for cs in current_shape]\n",
    "                # here w eare doing a downsampling operation, which is a patching operation.\n",
    "                # We record the current shape\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(current_n_filters),\n",
    "            nn.Linear(current_n_filters, 10)\n",
    "        )\n",
    "        # self.norm2 = nn.InstanceNorm2d(current_n_filters)\n",
    "        # # This brings it down to one channel / class\n",
    "        # self.bottleneck = nn.Conv2d(in_channels=current_n_filters, out_channels=10, \n",
    "        #                                   kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        x = self.stem(inputs)\n",
    "        # Apply a normalization after the initial patching:\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # Apply the main chunk of the network:\n",
    "        x = self.layers(x)\n",
    "\n",
    "        # Normalize and readout:\n",
    "        x = nn.functional.avg_pool2d(x, x.shape[2:])\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e5aa0a927e005eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.147616024Z",
     "start_time": "2024-02-22T21:15:51.112035319Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = Classifier(64, 4, 2)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.cuda()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# The first test will be to set the initial filter to a multiple of . Actually, Why don't I just convert the image to a 1 channel if color should not matter for these images.  I can then normalize the image as well.  \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 3 stages \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 2 blocks per stage\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/gpfs/projects/rjh/adrian/anaconda3/envs/ai-training/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "#model = Classifier(64, 4, 2)\n",
    "#model.cuda()\n",
    "# The first test will be to set the initial filter to a multiple of . Actually, Why don't I just convert the image to a 1 channel if color should not matter for these images.  I can then normalize the image as well.  \n",
    "# 3 stages \n",
    "# 2 blocks per stage\n",
    "model = Classifier(64, 3, 3)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10776dbedcca0cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.197492835Z",
     "start_time": "2024-02-22T21:15:51.146627206Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, val_bar):\n",
    "    # Set the model to evaluation mode \n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    # We can save computation and memory by not calcualting the gradients\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, Y).item()\n",
    "            correct += torch.sum(torch.argmax(pred, dim=1) == Y).item()\n",
    "            val_bar.update()\n",
    "    loss /= num_batches\n",
    "    correct /= (size * batch_size)\n",
    "    accuracy = 100 * correct\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2a7d2f40dc0a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198199270Z",
     "start_time": "2024-02-22T21:15:51.191451146Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, progress_bar):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        l = loss_fn(pred, Y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4976e7c1d475a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198599609Z",
     "start_time": "2024-02-22T21:15:51.191599221Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a42a98bcc0551337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198921429Z",
     "start_time": "2024-02-22T21:15:51.191651698Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a50c08bd5881718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.559466513Z",
     "start_time": "2024-02-22T21:15:51.191688740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: 100%|██████████| 313/313 [01:17<00:00,  4.04it/s]\n",
      "Validate (train) Epoch 0: 100%|██████████| 313/313 [00:26<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss: 1.636, accuracy: 38.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 0: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation loss: 1.636, accuracy: 37.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 1: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss: 1.279, accuracy: 54.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 1: 100%|██████████| 79/79 [00:06<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss: 1.306, accuracy: 52.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 2: 100%|██████████| 313/313 [00:26<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: training loss: 1.064, accuracy: 62.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 2: 100%|██████████| 79/79 [00:06<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: validation loss: 1.102, accuracy: 59.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 3: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: training loss: 0.847, accuracy: 70.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 3: 100%|██████████| 79/79 [00:06<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: validation loss: 0.912, accuracy: 67.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 4: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: training loss: 0.718, accuracy: 74.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 4: 100%|██████████| 79/79 [00:06<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: validation loss: 0.813, accuracy: 70.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 5: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: training loss: 0.587, accuracy: 79.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 5: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: validation loss: 0.700, accuracy: 74.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 6: 100%|██████████| 313/313 [00:26<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: training loss: 0.522, accuracy: 81.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 6: 100%|██████████| 79/79 [00:06<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: validation loss: 0.656, accuracy: 75.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 7: 100%|██████████| 313/313 [00:26<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: training loss: 0.428, accuracy: 85.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 7: 100%|██████████| 79/79 [00:06<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: validation loss: 0.606, accuracy: 77.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 8: 100%|██████████| 313/313 [00:26<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: training loss: 0.380, accuracy: 86.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 8: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: validation loss: 0.594, accuracy: 78.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 9: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: training loss: 0.336, accuracy: 88.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 9: 100%|██████████| 79/79 [00:06<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: validation loss: 0.546, accuracy: 80.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 10: 100%|██████████| 313/313 [00:26<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: training loss: 0.298, accuracy: 89.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 10: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: validation loss: 0.576, accuracy: 80.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 11: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 11: 100%|██████████| 313/313 [00:26<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss: 0.272, accuracy: 90.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 11: 100%|██████████| 79/79 [00:06<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: validation loss: 0.585, accuracy: 80.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 12: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 12: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: training loss: 0.250, accuracy: 91.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 12: 100%|██████████| 79/79 [00:06<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: validation loss: 0.585, accuracy: 79.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 13: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 13: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: training loss: 0.211, accuracy: 92.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 13: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: validation loss: 0.587, accuracy: 80.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 14: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 14: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: training loss: 0.232, accuracy: 91.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 14: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: validation loss: 0.591, accuracy: 80.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 15: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 15: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: training loss: 0.190, accuracy: 93.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 15: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: validation loss: 0.582, accuracy: 80.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 16: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 16: 100%|██████████| 313/313 [00:26<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: training loss: 0.142, accuracy: 95.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 16: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: validation loss: 0.525, accuracy: 82.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 17: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 17: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: training loss: 0.142, accuracy: 95.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 17: 100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: validation loss: 0.571, accuracy: 81.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 18: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 18: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: training loss: 0.138, accuracy: 95.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 18: 100%|██████████| 79/79 [00:06<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: validation loss: 0.582, accuracy: 81.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 19: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 19: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: training loss: 0.137, accuracy: 95.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 19: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: validation loss: 0.605, accuracy: 81.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 20: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 20: 100%|██████████| 313/313 [00:26<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss: 0.106, accuracy: 96.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 20: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: validation loss: 0.575, accuracy: 82.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 21: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 21: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: training loss: 0.102, accuracy: 96.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 21: 100%|██████████| 79/79 [00:06<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: validation loss: 0.555, accuracy: 83.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 22: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 22: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: training loss: 0.126, accuracy: 95.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 22: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: validation loss: 0.628, accuracy: 81.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 23: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 23: 100%|██████████| 313/313 [00:26<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: training loss: 0.093, accuracy: 96.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 23: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: validation loss: 0.581, accuracy: 82.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 24: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 24: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: training loss: 0.087, accuracy: 96.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 24: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: validation loss: 0.567, accuracy: 82.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 25: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 25: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: training loss: 0.105, accuracy: 96.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 25: 100%|██████████| 79/79 [00:06<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: validation loss: 0.606, accuracy: 82.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 26: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 26: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss: 0.105, accuracy: 96.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 26: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: validation loss: 0.634, accuracy: 82.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 27: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 27: 100%|██████████| 313/313 [00:26<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: training loss: 0.094, accuracy: 96.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 27: 100%|██████████| 79/79 [00:06<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: validation loss: 0.620, accuracy: 82.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 28: 100%|██████████| 313/313 [01:20<00:00,  3.87it/s]\n",
      "Validate (train) Epoch 28: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: training loss: 0.083, accuracy: 97.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 28: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: validation loss: 0.617, accuracy: 82.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 29: 100%|██████████| 313/313 [01:20<00:00,  3.88it/s]\n",
      "Validate (train) Epoch 29: 100%|██████████| 313/313 [00:26<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: training loss: 0.090, accuracy: 96.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 29: 100%|██████████| 79/79 [00:06<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: validation loss: 0.642, accuracy: 82.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for j in range(epochs):\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Train Epoch {j}\") as train_bar:\n",
    "        train_one_epoch(train_dataloader, model, loss_fn, optimizer, train_bar)\n",
    "\n",
    "    # checking on the training loss and accuracy once per epoch\n",
    "\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Validate (train) Epoch {j}\") as train_eval:\n",
    "        acc, loss = evaluate(train_dataloader, model, loss_fn, train_eval)\n",
    "\n",
    "        print(f\"Epoch {j}: training loss: {loss:.3f}, accuracy: {acc:.3f}\")\n",
    "    with tqdm(total=len(validation_dataloader), position=0, leave=True, desc=f\"Validate Epoch {j}\") as val_bar:\n",
    "        acc_val, loss_val = evaluate(validation_dataloader, model, loss_fn, val_bar)\n",
    "        print(f\"Epoch {j}: validation loss: {loss_val:.3f}, accuracy: {acc_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e79b6b343512be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.891325461Z",
     "start_time": "2024-02-22T22:12:59.580576774Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 22 17:12:59 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   84C    P0              27W /  45W |   3246MiB /  4096MiB |     52%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A     26618      C   ...aconda3/envs/ai-training/bin/python      134MiB |\r\n",
      "|    0   N/A  N/A     94500      C   ...aconda3/envs/ai-training/bin/python     3104MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b8ee8af9b1e3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.939794576Z",
     "start_time": "2024-02-22T22:12:59.895494283Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea295f519af3b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.940555766Z",
     "start_time": "2024-02-22T22:12:59.939454420Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
