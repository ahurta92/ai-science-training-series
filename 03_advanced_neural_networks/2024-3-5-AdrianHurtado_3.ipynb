{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc907c456d5a66d",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.transforms import v2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6418e67cee10648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:50.483216869Z",
     "start_time": "2024-02-22T21:15:49.379520325Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrianhurtado/miniforge3/envs/ai_train/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=v2.Compose([\n",
    "        v2.ToTensor(),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomResizedCrop(size=32, scale=(0.85, 1.0), antialias=False),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    ])\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=v2.Compose([\n",
    "        v2.ToTensor(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# split the training data into training and validation\n",
    "training_data, validation_data = torch.utils.data.random_split(training_data, [.8, .2], generator=torch.Generator().manual_seed(42))\n",
    "batch_size = 128\n",
    "\n",
    "# Create the dataloaders\n",
    "\n",
    "train_dataloader = DataLoader(training_data,\n",
    "                              batch_size=batch_size,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)\n",
    "validation_dataloader = DataLoader(validation_data,\n",
    "                                   batch_size=batch_size,\n",
    "                                   pin_memory=True,  # copy the data to the GPU\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=4)  # number of subprocesses to use for data loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ae569cf589332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.085870399Z",
     "start_time": "2024-02-22T21:15:50.483567162Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c78289d71a5d2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.086426714Z",
     "start_time": "2024-02-22T21:15:51.083335957Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a2af455b60f988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.100515378Z",
     "start_time": "2024-02-22T21:15:51.086144959Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(X, Y):\n",
    "    # CIFAR-10 is *color*\n",
    "    return X.view(-1, 3, 32, 32).to(device), Y.to(device)\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "\n",
    "train_dataloader = WrappedDataLoader(train_dataloader, preprocess)\n",
    "validation_dataloader = WrappedDataLoader(validation_dataloader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66aded01-6155-4052-bb44-1f62c6c2cefd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.133065213Z",
     "start_time": "2024-02-22T21:15:51.105871866Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Lets try a downsampler with convol\n",
    "class Downsampler(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        kernel_size=3\n",
    "        stride=1\n",
    "        padding=1 # keep the same size at the end\n",
    "        super(Downsampler, self).__init__()\n",
    "\n",
    "        layers=[\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2)]\n",
    "        self.downsample=nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.downsample(inputs)\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"This block of operations is loosely based on this paper:\n",
    "    start with an input with a 7 by 7 kernel, however with same padding it will not change the size of the image.\n",
    "    Then we apply a normalization layer, and follow with 4 filters, aka patches,per channel.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, shape):\n",
    "        super(ConvNextBlock, self).__init__()\n",
    "        # Depthwise, seperable convolution with a large number of output filters:\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=in_channels,\n",
    "                               groups=in_channels,# this is what makes it seperable? in_channel number of groups\n",
    "                               kernel_size=[7, 7],\n",
    "                               padding='same')# keep the same size\n",
    "        #This is like an expand, \n",
    "\n",
    "        self.norm = nn.LayerNorm([in_channels, *shape])\n",
    "        # Two more convolutions:\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=4 * in_channels,\n",
    "                               kernel_size=1)\n",
    "        # Then we do the unrolling of the patches, and apply a non-linear activation function.\n",
    "        self.conv3 = nn.Conv2d(in_channels=4 * in_channels,\n",
    "                               out_channels=in_channels,\n",
    "                               kernel_size=1\n",
    "                               )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.norm(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.gelu(x)\n",
    "        x = self.conv3(x)\n",
    "        # This makes it a residual network:\n",
    "        return x + inputs\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_initial_filters, n_stages, blocks_per_stage):\n",
    "        super(Classifier, self).__init__()\n",
    "        # our first example is set with 64,4,2 meaning 64 initial filters, 4 stages, 2 blocks per stage\n",
    "        # This is a downsampling convolution that will produce patches of output.\n",
    "        # This is similar to what vision transformers do to tokenize the images.\n",
    "        self.stem = nn.Conv2d(in_channels=3,\n",
    "                              out_channels=n_initial_filters,\n",
    "                              kernel_size=1,\n",
    "                              stride=1)\n",
    "        # Here is the initial convolution which takes our 32 x 32 image with 3 channels and \n",
    "        # converts it to 64 channels with a 1x1 convolution\n",
    "\n",
    "        # In other words, this stem is a patching operation that converts the input image into a set of patches.\n",
    "        # 3 to 64.  maybe here it makes sense to make n_intial_filters = 3 * filter_per_channel.. say 32\n",
    "\n",
    "        current_shape = [32, 32]\n",
    "        self.norm1 = nn.LayerNorm([n_initial_filters, *current_shape])\n",
    "        # self.norm1 = WrappedLayerNorm()\n",
    "        current_n_filters = n_initial_filters\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for i, n_blocks in enumerate(range(n_stages)):\n",
    "            # Add a convnext block series:\n",
    "            for _ in range(blocks_per_stage):\n",
    "                self.layers.append(ConvNextBlock(in_channels=current_n_filters, shape=current_shape))\n",
    "            # Add a downsampling layer:\n",
    "            if i != n_stages - 1:\n",
    "                # Skip downsampling if it's the last layer!\n",
    "                self.layers.append(Downsampler(\n",
    "                    in_channels=current_n_filters,\n",
    "                    out_channels=2 * current_n_filters,\n",
    "                )\n",
    "                )\n",
    "                # Double the number of filters:\n",
    "                current_n_filters = 2 * current_n_filters\n",
    "                # Cut the shape in half:\n",
    "                current_shape = [cs // 2 for cs in current_shape]\n",
    "                # here w eare doing a downsampling operation, which is a patching operation.\n",
    "                # We record the current shape\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(current_n_filters),\n",
    "            nn.Linear(current_n_filters, 10)\n",
    "        )\n",
    "        # self.norm2 = nn.InstanceNorm2d(current_n_filters)\n",
    "        # # This brings it down to one channel / class\n",
    "        # self.bottleneck = nn.Conv2d(in_channels=current_n_filters, out_channels=10, \n",
    "        #                                   kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        x = self.stem(inputs)\n",
    "        # Apply a normalization after the initial patching:\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # Apply the main chunk of the network:\n",
    "        x = self.layers(x)\n",
    "\n",
    "        # Normalize and readout:\n",
    "        x = nn.functional.avg_pool2d(x, x.shape[2:])\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5aa0a927e005eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.147616024Z",
     "start_time": "2024-02-22T21:15:51.112035319Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (stem): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (norm1): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "  (layers): Sequential(\n",
       "    (0): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (norm): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (norm): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ConvNextBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=64)\n",
       "      (norm): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): Downsampler(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvNextBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=128)\n",
       "      (norm): LayerNorm((128, 16, 16), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): ConvNextBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=128)\n",
       "      (norm): LayerNorm((128, 16, 16), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (6): ConvNextBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=128)\n",
       "      (norm): LayerNorm((128, 16, 16), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (7): Downsampler(\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNextBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=256)\n",
       "      (norm): LayerNorm((256, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (9): ConvNextBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=256)\n",
       "      (norm): LayerNorm((256, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (10): ConvNextBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=same, groups=256)\n",
       "      (norm): LayerNorm((256, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "      (conv2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Classifier(64, 4, 2)\n",
    "#model.cuda()\n",
    "# The first test will be to set the initial filter to a multiple of . Actually, Why don't I just convert the image to a 1 channel if color should not matter for these images.  I can then normalize the image as well.  \n",
    "# 3 stages \n",
    "# 2 blocks per stage\n",
    "model = Classifier(64, 3, 3)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10776dbedcca0cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.197492835Z",
     "start_time": "2024-02-22T21:15:51.146627206Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, val_bar):\n",
    "    # Set the model to evaluation mode \n",
    "    model.eval()\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    # We can save computation and memory by not calcualting the gradients\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, Y).item()\n",
    "            correct += torch.sum(torch.argmax(pred, dim=1) == Y).item()\n",
    "            val_bar.update()\n",
    "    loss /= num_batches\n",
    "    correct /= (size * batch_size)\n",
    "    accuracy = 100 * correct\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2a7d2f40dc0a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198199270Z",
     "start_time": "2024-02-22T21:15:51.191451146Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, model, loss_fn, optimizer, progress_bar):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        l = loss_fn(pred, Y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4976e7c1d475a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198599609Z",
     "start_time": "2024-02-22T21:15:51.191599221Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42a98bcc0551337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T21:15:51.198921429Z",
     "start_time": "2024-02-22T21:15:51.191651698Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a50c08bd5881718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.559466513Z",
     "start_time": "2024-02-22T21:15:51.191688740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:31<00:00,  3.41it/s]\n",
      "Validate (train) Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss: 1.184, accuracy: 57.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation loss: 1.198, accuracy: 56.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:43<00:00,  3.01it/s]\n",
      "Validate (train) Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:33<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss: 0.781, accuracy: 72.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss: 0.811, accuracy: 70.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:39<00:00,  3.13it/s]\n",
      "Validate (train) Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:32<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: training loss: 0.626, accuracy: 78.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: validation loss: 0.678, accuracy: 75.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:38<00:00,  3.17it/s]\n",
      "Validate (train) Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:33<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: training loss: 0.482, accuracy: 83.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: validation loss: 0.568, accuracy: 79.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:45<00:00,  2.96it/s]\n",
      "Validate (train) Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: training loss: 0.423, accuracy: 85.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: validation loss: 0.527, accuracy: 80.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: training loss: 0.406, accuracy: 85.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: validation loss: 0.537, accuracy: 80.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: training loss: 0.307, accuracy: 88.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: validation loss: 0.473, accuracy: 82.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: training loss: 0.271, accuracy: 90.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: validation loss: 0.444, accuracy: 84.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: training loss: 0.237, accuracy: 91.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: validation loss: 0.448, accuracy: 84.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: training loss: 0.213, accuracy: 92.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: validation loss: 0.434, accuracy: 85.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: training loss: 0.178, accuracy: 93.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: validation loss: 0.434, accuracy: 84.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 11: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 11: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss: 0.189, accuracy: 93.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: validation loss: 0.480, accuracy: 84.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 12: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 12: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: training loss: 0.154, accuracy: 94.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: validation loss: 0.438, accuracy: 85.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 13: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 13: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: training loss: 0.135, accuracy: 95.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: validation loss: 0.436, accuracy: 85.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 14: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: training loss: 0.142, accuracy: 94.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: validation loss: 0.472, accuracy: 84.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 15: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: training loss: 0.117, accuracy: 95.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: validation loss: 0.452, accuracy: 85.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 16: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 16: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: training loss: 0.101, accuracy: 96.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: validation loss: 0.450, accuracy: 86.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 17: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: training loss: 0.130, accuracy: 95.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 17: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: validation loss: 0.503, accuracy: 84.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 18: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: training loss: 0.093, accuracy: 96.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 18: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: validation loss: 0.463, accuracy: 85.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 19: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: training loss: 0.132, accuracy: 95.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 19: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: validation loss: 0.536, accuracy: 85.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss: 0.093, accuracy: 96.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 20: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: validation loss: 0.468, accuracy: 86.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 21: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 21: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: training loss: 0.089, accuracy: 96.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 21: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: validation loss: 0.482, accuracy: 86.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 22: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 22: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: training loss: 0.071, accuracy: 97.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 22: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: validation loss: 0.465, accuracy: 86.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 23: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 23: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: training loss: 0.087, accuracy: 96.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 23: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: validation loss: 0.495, accuracy: 86.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 24: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 24: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: training loss: 0.058, accuracy: 97.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 24: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: validation loss: 0.463, accuracy: 86.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 25: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: training loss: 0.065, accuracy: 97.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 25: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: validation loss: 0.461, accuracy: 86.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 26: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 26: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: training loss: 0.076, accuracy: 97.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 26: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: validation loss: 0.514, accuracy: 86.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 27: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 27: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: training loss: 0.070, accuracy: 97.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 27: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: validation loss: 0.489, accuracy: 86.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 28: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 28: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:35<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: training loss: 0.064, accuracy: 97.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 28: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: validation loss: 0.481, accuracy: 86.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 29: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [01:46<00:00,  2.93it/s]\n",
      "Validate (train) Epoch 29: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:34<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: training loss: 0.053, accuracy: 98.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validate Epoch 29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:08<00:00,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: validation loss: 0.465, accuracy: 87.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for j in range(epochs):\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Train Epoch {j}\") as train_bar:\n",
    "        train_one_epoch(train_dataloader, model, loss_fn, optimizer, train_bar)\n",
    "\n",
    "    # checking on the training loss and accuracy once per epoch\n",
    "\n",
    "    with tqdm(total=len(train_dataloader), position=0, leave=True, desc=f\"Validate (train) Epoch {j}\") as train_eval:\n",
    "        acc, loss = evaluate(train_dataloader, model, loss_fn, train_eval)\n",
    "\n",
    "        print(f\"Epoch {j}: training loss: {loss:.3f}, accuracy: {acc:.3f}\")\n",
    "    with tqdm(total=len(validation_dataloader), position=0, leave=True, desc=f\"Validate Epoch {j}\") as val_bar:\n",
    "        acc_val, loss_val = evaluate(validation_dataloader, model, loss_fn, val_bar)\n",
    "        print(f\"Epoch {j}: validation loss: {loss_val:.3f}, accuracy: {acc_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e79b6b343512be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.891325461Z",
     "start_time": "2024-02-22T22:12:59.580576774Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 22 17:12:59 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   84C    P0              27W /  45W |   3246MiB /  4096MiB |     52%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A     26618      C   ...aconda3/envs/ai-training/bin/python      134MiB |\r\n",
      "|    0   N/A  N/A     94500      C   ...aconda3/envs/ai-training/bin/python     3104MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b8ee8af9b1e3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.939794576Z",
     "start_time": "2024-02-22T22:12:59.895494283Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb57fb-9d04-40ec-9991-d4f427146071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T22:12:59.940555766Z",
     "start_time": "2024-02-22T22:12:59.939454420Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For this homework I made one main modification which was to change my downsampling strategy to using 2D max pooling.  The downsampling block contains 2 convolution + Gelu layers which maintain the kernel size until the last pass which does the max pooling.  The orinal downsampler was a bit similar using only the convolution as the downsampler using a stride of 2.  I'm not sure what will be better but I figured I'd can give this a try since pooling was introduce in the lecture.  Additionally I set my Classifier with 64 intial filter 3 stages and 3 blocks per stage which Reduces the amount of downsampling but widens each layer compared to the original 4 stages with 2 blocks per stage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea07240-9cfb-406d-abce-376a06b3f37d",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "In a previous version of a notebook I trained a model with the same 64,3,3 settings with the original downsampler and after 30 epochs I got 96% training accuracy and 82% validation accuracy.  In this case I get 87% training accuracy so I do see an improvement.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d247fd9-30e5-4040-81dc-bc4b9c4c5f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
